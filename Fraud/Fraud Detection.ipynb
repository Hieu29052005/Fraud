{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"hmeq-1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65500579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f56730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, recall_score, precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.core.algorithms as algos\n",
    "import scipy.stats.stats as stats\n",
    "import traceback\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['BAD']].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = df.isnull().mean().sort_values(ascending=False) * 100\n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [col for col in df.columns if df[col].dtype == 'object']\n",
    "numerical_features = [col for col in df.columns if df[col].dtype != 'object']\n",
    "\n",
    "print('Number of categorical features:', len(categorical_features))\n",
    "print('Number of numerical features:', len(numerical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e6f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đếm tần số của từng giá trị trong mỗi feature theo BAD\n",
    "for feature in categorical_features:\n",
    "    print(f\"\\nTần số của {feature} theo BAD:\")\n",
    "    freq_table = pd.crosstab(df[feature], df['BAD'], dropna=False)  # Giữ giá trị NaN nếu có\n",
    "    print(freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['REASON'] = df['REASON'].fillna('DebtCon')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['JOB'].isnull()) & (df['BAD'] == 0), 'JOB'] = 'Office'\n",
    "df.loc[(df['JOB'].isnull()) & (df['BAD'] == 1), 'JOB'] = 'Other'\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(f\"\\nTần số của {feature} theo BAD:\")\n",
    "    freq_table = pd.crosstab(df[feature], df['BAD'], dropna=False)  # Giữ giá trị NaN nếu có\n",
    "    print(freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f09334",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_value_bad_0 = df[df['BAD'] == 0]['VALUE'].median()\n",
    "median_value_bad_1 = df[df['BAD'] == 1]['VALUE'].median()\n",
    "\n",
    "# Điền giá trị thiếu theo BAD\n",
    "df.loc[(df['VALUE'].isna()) & (df['BAD'] == 0), 'VALUE'] = median_value_bad_0\n",
    "df.loc[(df['VALUE'].isna()) & (df['BAD'] == 1), 'VALUE'] = median_value_bad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_median_by_bad = ['CLNO', 'YOJ', 'CLAGE', 'NINQ', 'DELINQ', 'DEROG']\n",
    "for col in cols_median_by_bad:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    median_bad_0 = df[df['BAD'] == 0][col].median()\n",
    "    median_bad_1 = df[df['BAD'] == 1][col].median()\n",
    "    df.loc[(df[col].isna()) & (df['BAD'] == 0), col] = median_bad_0\n",
    "    df.loc[(df[col].isna()) & (df['BAD'] == 1), col] = median_bad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mortdue = ['CLNO', 'VALUE', 'LOAN', 'BAD', 'MORTDUE']\n",
    "df_mortdue_impute = df[features_mortdue].copy()\n",
    "\n",
    "# Đảm bảo chỉ số đồng bộ\n",
    "df_mortdue_impute.index = df.index\n",
    "\n",
    "# Xử lý giá trị không phải số\n",
    "for col in features_mortdue:\n",
    "    df_mortdue_impute[col] = pd.to_numeric(df_mortdue_impute[col], errors='coerce')\n",
    "\n",
    "# Kiểm tra NaN trước khi chạy KNN\n",
    "print(\"\\nSố lượng NaN trong các feature trước khi điền MORTDUE:\")\n",
    "print(df_mortdue_impute.isna().sum())\n",
    "\n",
    "# Áp dụng KNN Imputer\n",
    "imputer_mortdue = KNNImputer(n_neighbors=5)\n",
    "df_mortdue_filled = imputer_mortdue.fit_transform(df_mortdue_impute)\n",
    "\n",
    "# Chuyển đổi ngược về DataFrame\n",
    "df_mortdue_filled = pd.DataFrame(df_mortdue_filled, columns=features_mortdue, index=df.index)\n",
    "\n",
    "# Gán lại giá trị MORTDUE\n",
    "df['MORTDUE'] = df_mortdue_filled['MORTDUE']\n",
    "\n",
    "# 4. Kiểm tra số lượng giá trị thiếu sau khi điền\n",
    "print(\"\\nSố lượng giá trị thiếu trong MORTDUE sau khi điền:\", df['MORTDUE'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f13b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Điền DEBTINC bằng KNN Imputation\n",
    "features_debtinc = ['CLNO', 'MORTDUE', 'NINQ', 'LOAN', 'VALUE', 'BAD', 'DEBTINC']\n",
    "df_debtinc_impute = df[features_debtinc].copy()\n",
    "\n",
    "# Đảm bảo chỉ số đồng bộ\n",
    "df_debtinc_impute.index = df.index\n",
    "\n",
    "# Xử lý giá trị không phải số\n",
    "for col in features_debtinc:\n",
    "    df_debtinc_impute[col] = pd.to_numeric(df_debtinc_impute[col], errors='coerce')\n",
    "\n",
    "# Kiểm tra NaN trước khi chạy KNN\n",
    "print(\"\\nSố lượng NaN trong các feature trước khi điền DEBTINC:\")\n",
    "print(df_debtinc_impute.isna().sum())\n",
    "\n",
    "# Áp dụng KNN Imputer\n",
    "imputer_debtinc = KNNImputer(n_neighbors=5)\n",
    "df_debtinc_filled = imputer_debtinc.fit_transform(df_debtinc_impute)\n",
    "\n",
    "# Chuyển đổi ngược về DataFrame\n",
    "df_debtinc_filled = pd.DataFrame(df_debtinc_filled, columns=features_debtinc, index=df.index)\n",
    "\n",
    "# Gán lại giá trị DEBTINC\n",
    "df['DEBTINC'] = df_debtinc_filled['DEBTINC']\n",
    "\n",
    "# 4. Kiểm tra số lượng giá trị thiếu sau khi điền\n",
    "print(\"\\nSố lượng giá trị thiếu trong DEBTINC sau khi điền:\", df['DEBTINC'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78879ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính ma trận tương quan\n",
    "# Chọn chỉ các cột số để tính toán ma trận tương quan\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "# Vẽ heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16922c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc toàn bộ outlier theo IQR cho các biến số\n",
    "def remove_outliers_iqr(df_input, columns):\n",
    "    df_temp = df_input.copy()\n",
    "    for col in columns:\n",
    "        Q1 = df_temp[col].quantile(0.25)\n",
    "        Q3 = df_temp[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_temp = df_temp[(df_temp[col] >= lower_bound) & (df_temp[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Lấy danh sách các cột số (trừ cột target)\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop('BAD')\n",
    "\n",
    "# Áp dụng lọc outlier\n",
    "df_clean = remove_outliers_iqr(df, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_woe_iv(df, feature, target, bins=10):\n",
    "    # Chia bin nếu là continuous feature\n",
    "    if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "        df['bucket'] = pd.qcut(df[feature], q=bins, duplicates='drop')\n",
    "    else:\n",
    "        df['bucket'] = df[feature]\n",
    "\n",
    "    # Tạo bảng tổng hợp\n",
    "    woe_df = df.groupby('bucket').agg({target: ['sum', 'count']})\n",
    "    woe_df.columns = ['Bad', 'Total']\n",
    "    woe_df['Good'] = woe_df['Total'] - woe_df['Bad']\n",
    "\n",
    "    # Tính tỷ lệ % Good và % Bad\n",
    "    woe_df['% Good'] = woe_df['Good'] / woe_df['Good'].sum()\n",
    "    woe_df['% Bad'] = woe_df['Bad'] / woe_df['Bad'].sum()\n",
    "\n",
    "    # Tính WOE và IV\n",
    "    woe_df['WOE'] = np.log(woe_df['% Good'] / woe_df['% Bad'])\n",
    "    woe_df['IV'] = (woe_df['% Good'] - woe_df['% Bad']) * woe_df['WOE']\n",
    "\n",
    "    # Tổng IV cho toàn bộ feature\n",
    "    iv = woe_df['IV'].sum()\n",
    "\n",
    "    return iv, woe_df[['Bad', 'Good', 'Total', '% Good', '% Bad', 'WOE', 'IV']]\n",
    "\n",
    "# Danh sách các cột cần tính IV\n",
    "features = [\"DEBTINC\", \"MORTDUE\", \"VALUE\", \"DEROG\", \"CLAGE\", \"NINQ\", \"DELINQ\", \"YOJ\", \"CLNO\", \"REASON\", \"JOB\"]\n",
    "iv_scores = {}\n",
    "\n",
    "# Tính IV cho từng feature và lưu kết quả\n",
    "for feature in features:\n",
    "    # Check if feature exists in the dataframe before calculating IV\n",
    "    if feature in df.columns:\n",
    "        iv, detail = calculate_woe_iv(df, feature, \"BAD\")\n",
    "        # Only store and print if IV calculation was successful (iv is not 0 and detail is not None)\n",
    "        if detail is not None:\n",
    "            iv_scores[feature] = iv\n",
    "            print(f\"Feature: {feature}, IV: {iv:.4f}\")\n",
    "        else:\n",
    "            print(f\"Feature: {feature}, IV cannot be calculated (all target values are the same or missing).\")\n",
    "    else:\n",
    "        print(f\"Feature: {feature} not found in DataFrame.\")\n",
    "\n",
    "\n",
    "# Sắp xếp các feature theo IV từ cao xuống thấp\n",
    "# Convert the dictionary to a list of tuples for sorting\n",
    "iv_sorted = sorted(iv_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\nSorted IV scores:\") # This line is corrected\n",
    "for feature, iv in iv_sorted:\n",
    "    print(f\"{feature}: {iv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16021e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa cột 'REASON'\n",
    "df = df.drop('REASON', axis=1)\n",
    "df = df.drop('bucket', axis=1)\n",
    "\n",
    "# Kiểm tra lại các cột sau khi xóa\n",
    "print(\"Các cột sau khi xóa 'REASON':\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c6ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Điền missing value trước khi encode\n",
    "df[\"JOB\"] = df[\"JOB\"].fillna(\"Unknown\")\n",
    "\n",
    "# Thực hiện One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=[\"JOB\"], drop_first=True)\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.filter(like=\"JOB_\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead0e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi tất cả các cột JOB_* từ boolean về integer\n",
    "job_cols = df.filter(like=\"JOB_\").columns\n",
    "df[job_cols] = df[job_cols].astype(int)\n",
    "# Kiểm tra lại\n",
    "print(df[job_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"BAD\"])\n",
    "y = df[\"BAD\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra kiểu dữ liệu của các cột\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b055be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols = X_train.columns\n",
    "X_train[cols] = scaler.fit_transform(X_train[cols])\n",
    "X_test[cols] = scaler.transform(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train,y_train = sm.fit_resample(X_train,y_train)\n",
    "print(\"Dimension of X_train_sm Shape:\", X_train.shape)\n",
    "print(\"Dimension of y_train_sm Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d75e6",
   "metadata": {},
   "source": [
    "1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38930ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1', C=0.9, solver='saga', n_jobs=-1)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Accuracy of TEST data: {:.2f}%\".format(100 * accuracy_score(y_test, y_test_pred)))\n",
    "    print(\"F1 Score of TEST data: {:.2f}%\".format(100 * f1_score(y_test, y_test_pred, average=\"macro\")))\n",
    "    print(\"Recall of TEST data: {:.2f}%\".format(100 * recall_score(y_test, y_test_pred, average=\"macro\")))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"RMSE: \", rmse)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_test_pred, average=None)\n",
    "    print(\"ROC AUC score: \", roc_auc)\n",
    "\n",
    "evaluation(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f23e83",
   "metadata": {},
   "source": [
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_rfr = RandomForestClassifier(random_state=42,oob_score=True)\n",
    "regr_rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(regr_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report, roc_auc_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# === Bước 1: Hàm Recall tùy chỉnh cho lớp 1 (BAD) ===\n",
    "def custom_recall_score(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "recall_scorer = make_scorer(custom_recall_score)\n",
    "\n",
    "# === Bước 2: Hàm objective cho Optuna ===\n",
    "def objective(trial):\n",
    "    # Tập siêu tham số cho RandomForest\n",
    "    params = {\n",
    "        \"classifier__n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"classifier__max_depth\": trial.suggest_int(\"max_depth\", 2, 22),\n",
    "        \"classifier__min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"classifier__min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        \"classifier__max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        \"classifier__bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"classifier__ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1)\n",
    "    }\n",
    "\n",
    "    # Tạo pipeline với SMOTE và RandomForestClassifier\n",
    "    pipeline = ImbPipeline([\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    pipeline.set_params(**params)\n",
    "\n",
    "    # Tính điểm Recall trung bình từ 5-fold cross-validation\n",
    "    recall = cross_val_score(pipeline, X_train, y_train, scoring=recall_scorer, cv=5).mean()\n",
    "    return recall\n",
    "\n",
    "# === Bước 3: Tạo và chạy Optuna study ===\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500, timeout=600)\n",
    "\n",
    "# === Bước 4: In kết quả tốt nhất ===\n",
    "print(\"✅ Best Recall (train CV):\", study.best_value)\n",
    "print(\"📌 Best hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# === Bước 5: Huấn luyện lại mô hình với các siêu tham số tốt nhất ===\n",
    "best_params = {key.replace(\"classifier__\", \"\"): value for key, value in study.best_params.items()}\n",
    "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Tạo pipeline cho huấn luyện cuối cùng\n",
    "final_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', best_rf_model)\n",
    "])\n",
    "\n",
    "# Huấn luyện mô hình trên toàn bộ tập train\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# === Bước 6: Hàm evaluation tùy chỉnh ===\n",
    "def evaluation(model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Dự đoán xác suất cho ROC AUC\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "\n",
    "    # In kết quả cho tập test\n",
    "    print(\"\\n==================================================\")\n",
    "    print(\"Evaluation for Test Data\")\n",
    "    print(\"==================================================\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(f\"Accuracy of TEST data: {100 * np.mean(y_test_pred == y_test):.2f}\")\n",
    "    print(f\"Recall of TEST data (class 1): {100 * recall_score(y_test, y_test_pred, pos_label=1):.2f}\")\n",
    "\n",
    "    # ROC AUC score (nếu có xác suất)\n",
    "    if y_test_proba is not None:\n",
    "        print(f\"ROC AUC score: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "    # RMSE (dựa trên xác suất, nếu có)\n",
    "    if y_test_proba is not None:\n",
    "        rmse = np.sqrt(np.mean((y_test - y_test_proba) ** 2))\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# === Bước 7: Đánh giá mô hình tốt nhất ===\n",
    "print(\"\\n==================================================\")\n",
    "print(\"Evaluation for the best Random Forest Model\")\n",
    "evaluation(final_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62235ea7",
   "metadata": {},
   "source": [
    "3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213833d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59626e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report, roc_auc_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    " \n",
    "# Giả định X_train, y_train, X_test, y_test đã được định nghĩa\n",
    "# Nếu chưa có, bạn cần thêm đoạn mã chia dữ liệu:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# === Bước 1: Hàm Recall tùy chỉnh cho lớp 1 (BAD) ===\n",
    "def custom_recall_score(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=1)\n",
    " \n",
    "recall_scorer = make_scorer(custom_recall_score)\n",
    " \n",
    "# === Bước 2: Hàm objective cho Optuna ===\n",
    "def objective(trial):\n",
    "    # Tập siêu tham số cần tìm (giới hạn max_depth để giảm overfitting)\n",
    "    params = {\n",
    "        \"classifier__criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        \"classifier__max_depth\": trial.suggest_int(\"max_depth\", 2, 22),  # Giảm từ 40 xuống 20\n",
    "        \"classifier__min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"classifier__min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        \"classifier__max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        \"classifier__ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1)  # Thêm ccp_alpha\n",
    "    }\n",
    " \n",
    "    # Tạo pipeline với SMOTE và DecisionTreeClassifier\n",
    "    pipeline = ImbPipeline([\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "    ])\n",
    "    pipeline.set_params(**params)\n",
    " \n",
    "    # Tính điểm Recall trung bình từ 5-fold cross-validation\n",
    "    recall = cross_val_score(pipeline, X_train, y_train, scoring=recall_scorer, cv=5).mean()\n",
    "    return recall\n",
    " \n",
    "# === Bước 3: Tạo và chạy Optuna study ===\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500, timeout=600)  # Giảm n_trials từ 20000 xuống 100\n",
    " \n",
    "# === Bước 4: In kết quả tốt nhất ===\n",
    "print(\"✅ Best Recall (train CV):\", study.best_value)\n",
    "print(\"📌 Best hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    " \n",
    "# === Bước 5: Huấn luyện lại mô hình với các siêu tham số tốt nhất ===\n",
    "best_params = {key.replace(\"classifier__\", \"\"): value for key, value in study.best_params.items()}\n",
    "best_tree_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    " \n",
    "# Tạo pipeline cho huấn luyện cuối cùng\n",
    "final_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', best_tree_model)\n",
    "])\n",
    " \n",
    "# Huấn luyện mô hình trên toàn bộ tập train\n",
    "final_pipeline.fit(X_train, y_train)\n",
    " \n",
    "# === Bước 6: Hàm evaluation tùy chỉnh ===\n",
    "def evaluation(model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    # Dự đoán trên tập train và test\n",
    "    y_test_pred = model.predict(X_test)\n",
    " \n",
    "    # Dự đoán xác suất cho ROC AUC\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    " \n",
    "    # In kết quả cho tập test\n",
    "    print(\"\\n==================================================\")\n",
    "    print(\"Evaluation for Test Data\")\n",
    "    print(\"==================================================\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(f\"Accuracy of TEST data: {100 * np.mean(y_test_pred == y_test):.2f}\")\n",
    "    print(f\"Recall of TEST data (class 1): {100 * recall_score(y_test, y_test_pred, pos_label=1):.2f}\")\n",
    " \n",
    "    # ROC AUC score (nếu có xác suất)\n",
    "    if y_test_proba is not None:\n",
    "        print(f\"ROC AUC score: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    " \n",
    "    # RMSE (dựa trên xác suất, nếu có)\n",
    "    if y_test_proba is not None:\n",
    "        rmse = np.sqrt(np.mean((y_test - y_test_proba) ** 2))\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    " \n",
    "# === Bước 7: Đánh giá mô hình tốt nhất ===\n",
    "print(\"\\n==================================================\")\n",
    "print(\"Evaluation for the best Decision Tree Model\")\n",
    "evaluation(final_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c466b2",
   "metadata": {},
   "source": [
    "4. CatBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e343802",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42\n",
    ")\n",
    " \n",
    "cat_model.fit(X_train, y_train, early_stopping_rounds=50)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad137313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Nếu đầu ra là xác suất (continuous), cần chuyển sang nhãn (binary)\n",
    "    if y_test_pred.ndim == 2 and y_test_pred.shape[1] == 1:\n",
    "        y_test_pred = y_test_pred.ravel()  # flatten if shape is (n_samples, 1)\n",
    "\n",
    "    y_test_pred_class = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred_class))\n",
    "    print(\"Accuracy of TEST data: {:.2f}%\".format(100 * accuracy_score(y_test, y_test_pred_class)))\n",
    "    print(\"F1 Score of TEST data: {:.2f}%\".format(100 * f1_score(y_test, y_test_pred_class, average=\"macro\")))\n",
    "    print(\"Recall of TEST data: {:.2f}%\".format(100 * recall_score(y_test, y_test_pred_class, average=\"macro\")))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"RMSE: \", rmse)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"ROC AUC score: \", roc_auc)\n",
    "\n",
    "evaluation(cat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21339432",
   "metadata": {},
   "source": [
    "5. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab17fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Khởi tạo và huấn luyện mô hình LightGBM\n",
    "light_model = LGBMClassifier(random_state=42)\n",
    "light_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29633962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Nếu đầu ra là xác suất (continuous), cần chuyển sang nhãn (binary)\n",
    "    if y_test_pred.ndim == 2 and y_test_pred.shape[1] == 1:\n",
    "        y_test_pred = y_test_pred.ravel()  # flatten if shape is (n_samples, 1)\n",
    "\n",
    "    y_test_pred_class = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred_class))\n",
    "    print(\"Accuracy of TEST data: {:.2f}%\".format(100 * accuracy_score(y_test, y_test_pred_class)))\n",
    "    print(\"F1 Score of TEST data: {:.2f}%\".format(100 * f1_score(y_test, y_test_pred_class, average=\"macro\")))\n",
    "    print(\"Recall of TEST data: {:.2f}%\".format(100 * recall_score(y_test, y_test_pred_class, average=\"macro\")))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"RMSE: \", rmse)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"ROC AUC score: \", roc_auc)\n",
    "\n",
    "evaluation(light_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52038738",
   "metadata": {},
   "source": [
    "6. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_model = XGBClassifier(use_label_encoder=False,eval_metric='logloss',random_state=42)\n",
    "x_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad136ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Nếu đầu ra là xác suất (continuous), cần chuyển sang nhãn (binary)\n",
    "    if y_test_pred.ndim == 2 and y_test_pred.shape[1] == 1:\n",
    "        y_test_pred = y_test_pred.ravel()  # flatten if shape is (n_samples, 1)\n",
    "\n",
    "    y_test_pred_class = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred_class))\n",
    "    print(\"Accuracy of TEST data: {:.2f}%\".format(100 * accuracy_score(y_test, y_test_pred_class)))\n",
    "    print(\"F1 Score of TEST data: {:.2f}%\".format(100 * f1_score(y_test, y_test_pred_class, average=\"macro\")))\n",
    "    print(\"Recall of TEST data: {:.2f}%\".format(100 * recall_score(y_test, y_test_pred_class, average=\"macro\")))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"RMSE: \", rmse)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"ROC AUC score: \", roc_auc)\n",
    "\n",
    "evaluation(x_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25253eef",
   "metadata": {},
   "source": [
    "7. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Khởi tạo các kỹ thuật resampling\n",
    "sampling_strategy = {0: 2384, 1:2384}\n",
    "over = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "pipeline = Pipeline(steps=[('over', over), ('under', under)])\n",
    "\n",
    "# Áp dụng kỹ thuật resampling vào tập huấn luyện\n",
    "X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "new_train_data = pd.concat([X_train_resampled, y_train_resampled], axis=1)\n",
    "print(new_train_data[['BAD']].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Chuẩn hóa dữ liệu (Đưa về mean = 0, variance = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)  # x <--   (x - mean(x_train))/std(x_train)  (Đảm bảo tập test được chuẩn hóa như tập train.)\n",
    "\n",
    "# Huấn luyện SVM với gamma = 1\n",
    "svm_rbf = SVC(kernel='rbf', C=2, gamma=1, class_weight='balanced',probability=True, random_state=42)\n",
    "svm_rbf.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "\n",
    "# Đánh giá trên tập train (sau resampling)\n",
    "y_train_pred = svm_rbf.predict(X_train_resampled_scaled)\n",
    "print(\"The evaluation of training set (using SMOTETomek):\")\n",
    "print(classification_report(y_train_resampled, y_train_pred))\n",
    "\n",
    "# Đánh giá trên tập test\n",
    "y_test_pred = svm_rbf.predict(X_test_scaled)\n",
    "print(\"\\nThe evaluation of test set:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "auc_train = roc_auc_score(y_train_resampled, y_train_pred)\n",
    "auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"AUC score trên tập train: {auc_train:.4f}\")\n",
    "print(f\"AUC score trên tập test: {auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a777a",
   "metadata": {},
   "source": [
    "8. Compare these model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(penalty='l1', C=0.9, solver='saga', n_jobs=-1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators = 266,max_depth = 9, min_samples_split = 2, min_samples_leaf = 4,max_features='sqrt', bootstrap = False, ccp_alpha = 0.0002841158182021458),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False,eval_metric='logloss',random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion = 'gini', max_depth = 21, min_samples_split = 6, min_samples_leaf = 1, max_features = None, ccp_alpha = 0.00015159440001651534),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=500,learning_rate=0.05,depth=6,eval_metric='AUC',random_seed=42),\n",
    "    \"SVM\": SVC(kernel='rbf', C=2, gamma=1, class_weight='balanced',probability=True, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name,model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test,y_pred),\n",
    "        \"Precision\": precision_score(y_test,y_pred),\n",
    "        \"Recall\": recall_score(y_test,y_pred),\n",
    "        \"F1 Score\": f1_score(y_test,y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test,y_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd94964",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"Training: {name}\")\n",
    "    res = evaluate_model(name,model,X_train,y_train,X_test,y_test)\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(by=\"AUC\",ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"Accuracy\", y=\"Model\", data=results_df, palette=\"coolwarm\")\n",
    "plt.title(\"Model Performance (AUC)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c846e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 11. Save best model and preprocessor ===\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the best model based on AUC\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Re-fit the best model (to ensure it's trained with all data)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# === 12. Prediction function for new samples ===\n",
    "def predict_sample(new_data):\n",
    "    \"\"\"\n",
    "    Predict using the saved model and scaler.\n",
    "    \n",
    "    Args:\n",
    "        new_data (DataFrame): New data with same structure as training data\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (prediction, probability)\n",
    "    \"\"\"\n",
    "    # Load model and scaler\n",
    "    model = joblib.load('best_model.pkl')\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    \n",
    "    # Preprocess the new data\n",
    "    # 1. Handle categoricals (JOB_* columns should already exist if using get_dummies)\n",
    "    # 2. Ensure column order matches training\n",
    "    new_data = new_data[X_train.columns]  # Reorder columns\n",
    "    \n",
    "    # Scale numerical features\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(new_data_scaled)\n",
    "    probability = model.predict_proba(new_data_scaled)[:, 1]\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "# === 13. Example usage ===\n",
    "# Create sample data (with all features including dummy columns)\n",
    "sample_data = pd.DataFrame({\n",
    "    'LOAN': [10000],\n",
    "    'MORTDUE': [20000],\n",
    "    'VALUE': [25000],\n",
    "    'DEROG': [0],\n",
    "    'DELINQ': [0],\n",
    "    'CLAGE': [100],\n",
    "    'NINQ': [1],\n",
    "    'CLNO': [5],\n",
    "    'DEBTINC': [35],\n",
    "    'YOJ': [5],\n",
    "    'JOB_Office': [0],\n",
    "    'JOB_Other': [1],\n",
    "    'JOB_ProfExe': [0],\n",
    "    'JOB_Sales': [0],\n",
    "    'JOB_Self': [0]\n",
    "}, index=[0])\n",
    "\n",
    "# Predict\n",
    "prediction, probability = predict_sample(sample_data)\n",
    "print(f\"\\nPrediction: {'BAD' if prediction[0] == 1 else 'GOOD'}\")\n",
    "print(f\"Probability: {probability[0]:.2f}\")\n",
    "\n",
    "# === 14. Detailed evaluation of best model ===\n",
    "print(\"\\n=== Best Model Evaluation ===\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAUC-ROC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
